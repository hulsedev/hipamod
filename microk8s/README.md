# Spark

Modeling resiliency in a large network of connected devices.

Adding a networking plug-in to most frameworks for workload allocations.

## Readings

References on either deploying Spark in standard and new settings.

- Usage of Spark at NASA, [slides](https://www.slideshare.net/SparkSummit/spark-at-nasajplchris-mattmann)
- Tutorial on [Apache Spark](https://www.tutorialspoint.com/apache_spark)
- Spark on Docker, [talk](https://databricks.com/session/lessons-learned-from-running-spark-on-docker)
- Paper on High Throughput Computing, [pdf](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.462.658&rep=rep1&type=pdf)